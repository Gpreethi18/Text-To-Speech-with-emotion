{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gpreethi18/Text-To-Speech-with-emotion/blob/main/Automated_AudioBook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrqAesQPG4lC",
        "outputId": "9e50df78-d888-42cd-9e1e-6a5cba295fcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjP328h7J71U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLWn44XOKC0F"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('dataset_2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3sQVLMqn-ln"
      },
      "source": [
        "Happy, Sad, Angry, Fear, Normal, Suprised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14px3IqnKN8s"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "478jMmYrSTif"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1yGgyC6Ked9"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCARCM1l-qIl"
      },
      "outputs": [],
      "source": [
        "df.fillna(1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AspFldWH-ySq"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wn2zZPQ-6yE"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psW1wuSRKou9"
      },
      "outputs": [],
      "source": [
        "df['Emotion'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ4pJpoALqpT"
      },
      "outputs": [],
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGQaN0OML2bc"
      },
      "outputs": [],
      "source": [
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUoXcgSQL7Im"
      },
      "outputs": [],
      "source": [
        "tokenized = df['Sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GHwmoBkMIh9"
      },
      "outputs": [],
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnbQjuF5MVaU"
      },
      "outputs": [],
      "source": [
        "np.array(padded).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYQG8XTxMXvT"
      },
      "outputs": [],
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77jNLN6lMb6p"
      },
      "outputs": [],
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j406qbAp03-A"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7xWE3qf3N1J"
      },
      "outputs": [],
      "source": [
        "ftf = last_hidden_states[0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBQGAtaa5Yms"
      },
      "outputs": [],
      "source": [
        "print(ftf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH7KJmbgMlHE"
      },
      "outputs": [],
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8Ljl-zS3wDM"
      },
      "outputs": [],
      "source": [
        "print(features.shape)\n",
        "print(features[0].shape)\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM0n7T-LOG8E"
      },
      "outputs": [],
      "source": [
        "labels = df['Emotion']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N26scHLXONkK"
      },
      "outputs": [],
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZAqQr-JOQkL"
      },
      "outputs": [],
      "source": [
        "# parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        "# grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        "# grid_search.fit(train_features, train_labels)\n",
        "\n",
        "# print('best parameters: ', grid_search.best_params_)\n",
        "# print('best scrores: ', grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMIOwULsO-ui"
      },
      "outputs": [],
      "source": [
        "lr_clf = LogisticRegression(C=5.263252631578947)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULIhiP_DQSwd"
      },
      "outputs": [],
      "source": [
        "lr_clf.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCrTCYYIQWr1",
        "outputId": "05e35ad6-1e54-4996-8508-26dc855deb07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-08cdf8ec52e7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'lr_clf' is not defined"
          ]
        }
      ],
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQpOfqnXQc66"
      },
      "outputs": [],
      "source": [
        "predictions = lr_clf.predict(test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPFuIgWpTwfn"
      },
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-0mnXBQT1vv"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(test_labels, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM3YMA3Q3ELV"
      },
      "outputs": [],
      "source": [
        "def transform(df):\n",
        "  tokenized = df['Sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "  max_len = 0\n",
        "  for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "  padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "  attention_mask = np.where(padded != 0, 1, 0)\n",
        "  input_ids = torch.tensor(padded)  \n",
        "  attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "  features = last_hidden_states[0][:,0,:].numpy()\n",
        "  return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGPTT9El8mam"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('lr_clf_model', 'wb') as files:\n",
        "    pickle.dump(lr_clf, files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzS3J_PMrhw8"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/ED/Pretrained models/lr_clf_model' , 'rb') as f:\n",
        "    lr_clf_2 = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqXuK5UkrN_H"
      },
      "outputs": [],
      "source": [
        "embed_array = ['__', 'normal_embed', 'angry_embed', 'fear_embed', 'happy_embed', '__', 'sad_embed', 'suprise_embed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zv6HMa2atCxG"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "git_repo_url = 'https://github.com/CorentinJ/Real-Time-Voice-Cloning.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # clone and install\n",
        "  !git clone -q --recursive {git_repo_url}\n",
        "  # install dependencies\n",
        "  !cd {project_name} && pip install -q -r requirements.txt\n",
        "  !pip install -q gdown\n",
        "  !apt-get install -qq libportaudio2\n",
        "  !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "\n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "\n",
        "from IPython.display import display, Audio, clear_output\n",
        "from IPython.utils import io\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from dl_colab_notebooks.audio import record_audio, upload_audio\n",
        "\n",
        "from synthesizer.inference import Synthesizer\n",
        "from encoder import inference as encoder\n",
        "from vocoder import inference as vocoder\n",
        "from pathlib import Path\n",
        "\n",
        "encoder.load_model(Path(\"/content/drive/MyDrive/ED/Pretrained models/encoder.pt\"))\n",
        "synthesizer = Synthesizer(Path(\"/content/drive/MyDrive/ED/Pretrained models/synthesizer.pt\"))\n",
        "vocoder.load_model(Path(\"/content/drive/MyDrive/ED/Pretrained models/vocoder.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZXCoBUyuRcy"
      },
      "outputs": [],
      "source": [
        "def synthesize(embed, text):\n",
        "  print(\"Synthesizing new audio...\")\n",
        "  #with io.capture_output() as captured:\n",
        "  specs = synthesizer.synthesize_spectrograms([text], [embed])\n",
        "  generated_wav = vocoder.infer_waveform(specs[0])\n",
        "  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
        "  clear_output()\n",
        "  display(Audio(generated_wav, rate=synthesizer.sample_rate, autoplay=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O4CdIs22yhp"
      },
      "outputs": [],
      "source": [
        "Sentence_list = ['''I AM happy but climate is bad''']\n",
        "values = {'Sentence':  Sentence_list}\n",
        "test_data = pd.DataFrame(values)\n",
        "test_feature = transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4PG-8hz71Nw"
      },
      "outputs": [],
      "source": [
        "prediction = lr_clf_2.predict(test_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G83PVrNl8DVA"
      },
      "outputs": [],
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlgI0_ul6Ns7"
      },
      "outputs": [],
      "source": [
        "embed = Path(\"/content/drive/MyDrive/ED/Pretrained models/\" + embed_array[int(prediction[0])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xqhv-oec6DrU"
      },
      "outputs": [],
      "source": [
        "with open(embed , 'rb') as f:\n",
        "    embedding_emo = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxB-o7jkvVmk"
      },
      "outputs": [],
      "source": [
        "synthesize(embedding_emo, Sentence_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"================= SVM =================\")\n",
        "from sklearn import svm\n",
        "\n",
        "#Create a svm Classifier\n",
        "lr_clf = svm.SVC(kernel='linear') # Linear Kernel\n",
        "lr_clf.fit(train_features, train_labels)\n",
        "lr_clf.score(test_features, test_labels)\n",
        "predictions = lr_clf.predict(test_features)\n",
        "print(predictions)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(test_labels, predictions))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NtSgwKr_FUsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=================RandomForestClassifier =================\")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "lr_clf = RandomForestClassifier(n_estimators=50, criterion=\"entropy\")\n",
        "lr_clf.fit(train_features, train_labels)\n",
        "lr_clf.score(test_features, test_labels)\n",
        "predictions = lr_clf.predict(test_features)\n",
        "print(predictions)\n",
        "print(accuracy_score(test_labels, predictions))"
      ],
      "metadata": {
        "id": "Jh0DUby4FaDN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}